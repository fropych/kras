# Задача 4

# Сравнение качества технического перевода

## 1\. Описание подхода

Для эксперимента был взят набор из 11 параграфов (абстрактов научных статей) по теме компьютерной графики, а именно **3D Gaussian Splatting** (современный метод рендеринга). Это узкоспециализированная тема с большим количеством непереведенной в общепринятый русский язык терминологии. Тексты были переведены тремя моделями: gemma-3n-e2b-it, gpt-oss-20 и grok-4.1-fast. Оценка проводилась вручную путем сравнения с эталонным пониманием терминологии в области Computer Vision/Graphics
## 2\. Запуск
Для установки зависимостей использовался uv  
Для запуска достаточно:
```
uv run main.py
```
## 3\. Таблица сравнения моделей

| Критерий | gemma-3n-e2b-it | gpt-oss-20  | grok-4.1-fast |
| :---- | :---- | :---- | :---- |
| **Терминология** | **Плохо.** Изобретает громоздкие описания ("модели разреженной точечной плотности" вместо Splatting). Делает ошибки в именах ("Махаलनбина") | **Хорошо.** Грамотно сохраняет устоявшиеся англицизмы (Splatting, Aliasing) или дает адекватный перевод ("Гауссовое распыление") | **Специфично.** Использует стратегию "Runglish" \- оставляет почти все существительные на английском, соединяя их русскими предлогами и глаголами |
| **Естественность** | **Низкая.** Встречаются программные сбои (код-свитчинг внутри слова "выrendering"), тяжеловесные конструкции | **Высокая.** Текст читается гладко, как литературный перевод, структура предложений адаптирована под русский язык | **Средняя.** Читается легко для IT-специалиста, но это не полноценный перевод |
| **Точность** | **Средняя.** Смысл передан, но детали искажаются из\-за попыток перевести непереводимое | **Высокая (с нюансом).** Смысл передан отлично, но замечена одна критическая галлюцинация ("беспартийных полётов") | **Высокая.** За счет отсутствия перевода терминов смысл оригинала сохранен максимально точно, риск искажения минимален |
| **Вердикт** | Аутсайдер | **Победитель** (для публикации) | Лучшая для быстрого чтения разработчиком |

## 4\. Примеры ответов и ошибок

**Пример 1: Термин "Gaussian Splatting"**

* *Оригинал:* "3D Gaussian splatting models..."  
* *Gemma:* "3D Гауссовы модели разреженной точечной плотности..." (Слишком длинно, термин invented)  
* *GPT-oss:* "Модели 3D Gaussian splatting..." (Корректно оставлен термин)  
* *Grok:* "Модели 3D Gaussian splatting..." (Корректно)

**Пример 2: Галлюцинации и сбои**

* *Оригинал:* "...artifact-free fly-throughs." (полеты камерой без артефактов изображения).  
* *Gemma:* "...беспроблемных пролетов." (Упрощение, но верно).  
* *GPT-oss:* "...беспартийных полётов по сцене." (**Критическая ошибка**: слово "artifact" вероятно спутано с чем-то политическим или модель "додумала" контекст, полностью исказив смысл).  
* *Grok:* "...fly-through без артефактов." (Технически верно).

**Пример 3: Технические сбои генерации**

* *Оригинал:* "...rendering fully..."  
* *Gemma:* "...выrendering полностью..." (Модель начала писать приставку "вы-" по-русски, а корень оставила английским).

## 5\. Выводы

1. **Какая модель лучше?** Для подготовки документации и статей лучшей является **gpt-oss-20**. Она строит наиболее грамотные русские предложения и правильно балансирует между переводом и сохранением английских терминов. Для личного использования разработчиком лучше **Grok**, так как она не портит терминологию попытками перевода.  
2. **Почему?** GPT лучше понимает контекст и стилистику русского языка. Gemma слишком буквально и неумело пытается переводить термины, делая текст наукообразным, но бессмысленным. Grok ленится переводить, что хорошо для точности, но плохо для задачи "перевод на русский".  
3. **Что удивило?**  
   * **Gemma** выдала "расстояния Махаलनбина" — вставила символ из деванагари (хинди?) в середину фамилии Махаланобис. Это явный токенизационный сбой.  
   * **GPT** сгенерировала "беспартийные полёты" вместо "полетов без артефактов". Это редкий пример семантической галлюцинации в модели высокого уровня, которая обычно надежна.  
   * **Стратегия Grok**: модель де\-факто отказалась переводить 40% текста (ключевые фразы), просто встроив их в русскую грамматику. Это интересное поведение "ленивого переводчика".

